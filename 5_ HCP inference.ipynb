{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZyvFNIKDKWc"
   },
   "outputs": [],
   "source": [
    "root = '' # change as needed\n",
    "data_root = root + 'data/'\n",
    "save_path = root + 'results/inference/'\n",
    "model_path = root + 'model' # path to the model reported in the paper (downloaded from Zenodo), you can change it to your own model\n",
    "sc_file = data_root + 'SC_dbs80HARDIFULL.mat'\n",
    "dbs_path = root + 'ds80_labels.csv'\n",
    "yeo_path = root + 'dbs802Yeo7.csv'\n",
    "!mkdir -p {save_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ofc61s4dBJJ"
   },
   "source": [
    "# 1) Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kibLWigFRt0F"
   },
   "outputs": [],
   "source": [
    "import mat73\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JwkYIeFzyQM7"
   },
   "outputs": [],
   "source": [
    "def get_ts_hcp_task(data_root):\n",
    "    '''\n",
    "    Reads the HCP task dataset.\n",
    "\n",
    "    Args:\n",
    "        data_root (str): Folder containing the data files (.mat).\n",
    "\n",
    "    Returns:\n",
    "        time_series (dict): Dictionary where the keys are the tasks and the values are the arrays.\n",
    "    '''\n",
    "    time_series = {}\n",
    "    time_series['memory'] = mat73.loadmat(data_root+'hcp1003_WM_LR_dbs80.mat')\n",
    "    time_series['gambling'] = mat73.loadmat(data_root+'hcp1003_GAMBLING_LR_dbs80.mat')\n",
    "    time_series['motor'] = mat73.loadmat(data_root+'hcp1003_MOTOR_LR_dbs80.mat')\n",
    "    time_series['language'] = mat73.loadmat(data_root+'hcp1003_LANGUAGE_LR_dbs80.mat')\n",
    "    time_series['social'] = mat73.loadmat(data_root+'hcp1003_SOCIAL_LR_dbs80.mat')\n",
    "    time_series['relational'] = mat73.loadmat(data_root+'hcp1003_RELATIONAL_LR_dbs80.mat')\n",
    "    time_series['emotion'] = mat73.loadmat(data_root+'hcp1003_EMOTION_LR_dbs80.mat')\n",
    "    time_series['rest'] = mat73.loadmat(data_root+'hcp1003_REST1_LR_dbs80.mat')\n",
    "    return time_series\n",
    "\n",
    "# Read time series\n",
    "data_ts = get_ts_hcp_task(data_root)\n",
    "# Get only useful data\n",
    "for k in data_ts.keys():\n",
    "  data_ts[k] = [i['dbs80ts'] for i in data_ts[k]['subject'] if type(i) is dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mjRLSaD3yQM-"
   },
   "outputs": [],
   "source": [
    "# Create time series dataframe\n",
    "rows = []\n",
    "for cohort, values in data_ts.items():\n",
    "    for id, value in enumerate(values):\n",
    "        rows.append({'cohort': cohort.capitalize(), 'bold': value, 'subject_id': id})\n",
    "del data_ts\n",
    "time_series = pd.DataFrame(rows)\n",
    "time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nz9QdSfZwBly"
   },
   "source": [
    "# 2) Signal filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dYt-6Qm3yQNC"
   },
   "outputs": [],
   "source": [
    "from scipy.signal import butter, detrend, filtfilt\n",
    "\n",
    "def demean(x,dim=0):\n",
    "    dims = x.size\n",
    "    return x - np.tile(np.mean(x,dim), dims)  # repmat(np.mean(x,dim),dimrep)\n",
    "\n",
    "def BandPassFilter(boldSignal, f_low, f_high, TR, k, removeStrongArtefacts=True):\n",
    "    # Convenience method to apply a filter (always the same one) to all areas in a BOLD signal. For a single,\n",
    "    # isolated area evaluation, better use the method below.\n",
    "    (N, Tmax) = boldSignal.shape\n",
    "    fnq = 1./(2.*TR)              # Nyquist frequency\n",
    "    Wn = [f_low/fnq, f_high/fnq]                                   # butterworth bandpass non-dimensional frequency\n",
    "    bfilt, afilt = butter(k,Wn, btype='band', analog=False)   # construct the filter\n",
    "    # bfilt = bfilt_afilt[0]; afilt = bfilt_afilt[1]  # numba doesn't like unpacking...\n",
    "    signal_filt = np.zeros(boldSignal.shape)\n",
    "    for seed in range(N):\n",
    "        if not np.isnan(boldSignal[seed, :]).any():  # No problems, go ahead!!!\n",
    "            ts = demean(detrend(boldSignal[seed, :]))  # Probably, we do not need to demean here, detrend already does the job...\n",
    "\n",
    "            if removeStrongArtefacts:\n",
    "                ts[ts>3.*np.std(ts)] = 3.*np.std(ts)    # Remove strong artefacts\n",
    "                ts[ts<-3.*np.std(ts)] = -3.*np.std(ts)  # Remove strong artefacts\n",
    "\n",
    "            signal_filt[seed,:] = filtfilt(bfilt, afilt, ts, padlen=3*(max(len(bfilt),len(afilt))-1))  # Band pass filter. padlen modified to get the same result as in Matlab\n",
    "        else:  # We've found problems, mark this region as \"problematic\", to say the least...\n",
    "            print(f'############ Warning!!! BandPassFilter: NAN found at region {seed} ############')\n",
    "            signal_filt[seed,0] = np.nan\n",
    "    return signal_filt\n",
    "\n",
    "def AmplitudeFilter(time_series):\n",
    "    return time_series/np.abs(time_series).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I4SgAnXzwRPq"
   },
   "outputs": [],
   "source": [
    "# Filters parameters\n",
    "TR = 2.0\n",
    "k = 2                                # 2nd order butterworth filter\n",
    "f_low = 0.008                        # lowpass frequency of filter\n",
    "f_high = 0.08                        # highpass\n",
    "\n",
    "# Apply filters\n",
    "time_series.loc[:,'bold'] = time_series['bold'].apply(BandPassFilter, args=(f_low, f_high, TR, k))\n",
    "time_series.loc[:,'bold'] = time_series['bold'].apply(AmplitudeFilter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZVvRKHvx9Cy"
   },
   "source": [
    "# 3) Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-KqlCgPLyQND"
   },
   "outputs": [],
   "source": [
    "t_use = 50\n",
    "stride = 50\n",
    "\n",
    "def create_windows(ts, size=1, stride=1):\n",
    "\tN, t = ts.shape\n",
    "\twindows = np.stack([ts[:, i:i+size] for i in reversed(list(range(t - size, -1, -stride)))], axis=0)\n",
    "\treturn windows\n",
    "\n",
    "# Extract windows and create a new dataframe\n",
    "all_windows = []\n",
    "for idx, row in time_series.iterrows():\n",
    "    windows = create_windows(row['bold'], t_use, stride)\n",
    "    for i, window in enumerate(windows):\n",
    "        all_windows.append({'cohort': row['cohort'], 'subject_id': row['subject_id'], 'window_id': i, 'window': window})\n",
    "    all_windows.append({'cohort': row['cohort'], 'subject_id': row['subject_id'], 'window_id': 'mean', 'window': windows.mean(axis=0)})\n",
    "del time_series\n",
    "\n",
    "# Create a new dataframe from the list of windows\n",
    "windows = pd.DataFrame(all_windows)\n",
    "del all_windows\n",
    "windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "URUIA-huyQND"
   },
   "outputs": [],
   "source": [
    "def get_filename(row):\n",
    "    if row['window_id'] == 'mean':\n",
    "        return f\"{row['cohort']}_{row['subject_id']}\"\n",
    "    else:\n",
    "        return f\"{row['cohort']}_{row['subject_id']}_{row['window_id']}\"\n",
    "\n",
    "# Add filenames to the df\n",
    "windows['filename'] = windows.apply(get_filename, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H61rPd9qyQNE"
   },
   "source": [
    "# 4) Time-series-to-image conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h4XlWpI8yQNE"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "ratio = 77\n",
    "def plot_ts(ts, path):\n",
    "    N, t = ts.shape\n",
    "    plt.figure(figsize=(t/ratio, N/ratio))\n",
    "    plt.imshow(ts, aspect='auto', cmap='viridis', vmin=-1, vmax=1)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vNvWlAptyQNE"
   },
   "outputs": [],
   "source": [
    "import tqdm, os\n",
    "\n",
    "if (not os.path.exists(save_path+'img/')):\n",
    "\tos.mkdir(save_path+'img/')\n",
    "\n",
    "# Create and save images\n",
    "for _, row in tqdm.tqdm(windows.iterrows(), total=len(windows)):\n",
    "    plot_ts(row['window'], f\"{save_path}/img/{row['filename']}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0yGmMtWW2aSy"
   },
   "source": [
    "# 5) Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2KO7EBlryQNF"
   },
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "a_min, a_max = -1, 1\n",
    "\n",
    "# Metric used\n",
    "def rmse_a(inp, targ):\n",
    "  return rmse(inp, targ)*100/(a_max-a_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DNjAyN_p66bI"
   },
   "outputs": [],
   "source": [
    "# Get inputs for the model\n",
    "image_list = save_path + '/img/' + windows['filename'].values + '.png'\n",
    "# Create dummy dataloader\n",
    "dls = ImageDataLoaders.from_path_func('', [0], lambda x: '0', bs=16, item_tfms=Resize((80, 50), method='squish'))\n",
    "# Load model\n",
    "learn = vision_learner(dls, 'convnext_tiny_in22k', n_out=80, y_range=(-1,1), loss_func=MSELossFlat).to_fp16()\n",
    "learn.load(model_path, device='cuda', weights_only=False)\n",
    "# Predict\n",
    "test_dl = learn.dls.test_dl(image_list, device='cuda')\n",
    "preds, _ = learn.get_preds(dl=test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q3Sq_DOsyQNF"
   },
   "outputs": [],
   "source": [
    "# Add predictions to the dataframe\n",
    "windows['pred'] = [p for p in preds.numpy()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cey3UEyqyQNF"
   },
   "source": [
    "# 6) Yeo networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zaHVqG80yQNF"
   },
   "outputs": [],
   "source": [
    "# Read names of the 80 ROIs\n",
    "dbs_names = pd.read_csv(dbs_path, sep=';').loc[:,'Rois'].values\n",
    "# Read asociated regions\n",
    "yeo_ids = pd.read_csv(yeo_path, header=None).iloc[0].values\n",
    "yeo_names = np.array([None, 'Visual', 'Somatomotor', 'Dorsal attention', 'Ventral attention', 'Limbic', 'Frontoparietal', 'Default'])\n",
    "# Filter non cortical regions\n",
    "dbs_names_cortex = dbs_names[np.r_[0:31, 49:80]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vwC19mBSyQNF"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "tasks_act = defaultdict(list)\n",
    "for c in np.unique(windows.cohort.values):\n",
    "    # Filter windows by task\n",
    "    selection = np.stack(windows[windows['cohort'] == c][windows['window_id'] == 'mean'].pred.values)\n",
    "    # Get the mean value for each ROI in a particular task\n",
    "    activations = selection.mean(axis=0)\n",
    "    # Filter non cortical regions\n",
    "    activations_cortex = activations[np.r_[0:31, 49:80]]\n",
    "    tasks_act[c].append(activations_cortex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0TqtMPlgyQNF"
   },
   "outputs": [],
   "source": [
    "comp = pd.DataFrame(columns=['Rest', 'Memory', 'Language', 'Gambling', 'Motor', 'Relational', 'Social', 'Emotion'])\n",
    "comp = comp.drop(columns=['Rest'])\n",
    "\n",
    "for c in tasks_act.keys():\n",
    "\tif c != 'Rest':\n",
    "\t\tnet_act = defaultdict(list)\n",
    "\t\tactivations_cortex = tasks_act[c][0]-tasks_act['Rest'][0]\n",
    "\t\tfor net,act in zip(yeo_names[yeo_ids], activations_cortex):\n",
    "\t\t\tif act>-20:\n",
    "\t\t\t\tnet_act[net].append(act)\n",
    "\t\tfor net in net_act.keys():\n",
    "\t\t\tcomp.loc[net, c] = [np.mean(net_act[net]), np.max(net_act[net])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BEFMPfx1yQNF"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "data = {'x': [], 'y': [], 'network': []}\n",
    "\n",
    "# Iterate over the df to extract y values and column/row labels\n",
    "for col in comp.columns:\n",
    "    for index, values in comp[col].items():\n",
    "        data['x'].append(col)\n",
    "        data['y'].append(values[0])\n",
    "        data['network'].append(index)\n",
    "\n",
    "# Convert data into a new df\n",
    "df_plot = pd.DataFrame(data)\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.stripplot(x='x', y='y', hue='network', data=df_plot, palette='deep', jitter=False, size=9, edgecolor='black', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "# Plot formatting\n",
    "plt.xlabel('Tasks', fontsize=14)\n",
    "plt.ylabel(r'Difference of mean bifurcation parameters', fontsize=14)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.grid(True, which='major', linestyle='--', alpha=0.6)\n",
    "plt.legend(title='Networks', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10, title_fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path+'networks.png', dpi=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oo8WerHrhzhE"
   },
   "source": [
    "# 7) Task separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a4ZXewYNzlY3"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from statannotations.Annotator import Annotator\n",
    "\n",
    "def pad_dicts(tests):\n",
    "    \"\"\"Ensure all dictionaries have the same length by padding with NaNs.\"\"\"\n",
    "    max_len = max(len(lst) for lst in tests.values())\n",
    "    return {key: np.pad(lst, (0, max_len - len(lst)), 'constant', constant_values=np.nan)\n",
    "            for key, lst in tests.items()}\n",
    "\n",
    "def plot_comparison_across_labels(tests, method=\"BH\", title='', x_label='', y_label='', fig_size=(12, 8), save_path='./'):\n",
    "\n",
    "\t# Prepare data\n",
    "\ttests = pad_dicts(tests)\n",
    "\tuse_labels = list(tests.keys())\n",
    "\tpairs = list(combinations(use_labels, 2))\n",
    "\tdf = pd.DataFrame(tests, columns=use_labels)\n",
    "\n",
    "\t# Set up figure and axes\n",
    "\tfig, (ax_table, ax_violin) = plt.subplots(2, 1, figsize=fig_size, gridspec_kw={'height_ratios': [1.2, 3]})\n",
    "\tsns.set_context(\"talk\")\n",
    "\n",
    "\t# Perform statistical comparisons and annotate\n",
    "\tannotator = Annotator(ax=ax_violin, data=df, pairs=pairs, order=use_labels)\n",
    "\tannotator.configure(test='Mann-Whitney', text_format='star', verbose=True)\n",
    "\tannotator.configure(comparisons_correction=method, correction_format=\"replace\")\n",
    "\tresults = annotator.apply_test()\n",
    "\n",
    "\t# Prints\n",
    "\tannotator.print_pvalue_legend()\n",
    "\tfor a in results.annotations:\n",
    "\t\ta.print_labels_and_content()\n",
    "\n",
    "\t# Create violin plot\n",
    "\tsns.violinplot(data=df, order=use_labels, ax=ax_violin, palette='deep', linewidth=1.2)\n",
    "\tax_violin.set_xlabel(x_label, fontsize=14)\n",
    "\tax_violin.set_ylabel(y_label, fontsize=14)\n",
    "\tax_violin.set_xticklabels(ax_violin.get_xticklabels(), fontsize=12)\n",
    "\n",
    "\t# Grid and despine for cleaner look\n",
    "\tsns.despine()\n",
    "\tax_violin.grid(True, which='major', linestyle='--', alpha=0.6)\n",
    "\n",
    "\t# Create a significance stars table\n",
    "\tstars_matrix = pd.DataFrame(\"\", index=df.columns[1:], columns=df.columns[:-1])\n",
    "\tfor result in results.annotations:\n",
    "\t\tc1, c2 = [str(struct[\"label\"]) for struct in result.structs]\n",
    "\t\tstars_matrix.loc[c2, c1] = result.text  # Insert stars\n",
    "\n",
    "\t# Plot the table above the violin plot\n",
    "\tbbox_v = ax_violin.get_position()\n",
    "\tnew_left = (bbox_v.x0 + bbox_v.x1) / 2 - 0.7 / 2\n",
    "\ttable = pd.plotting.table(ax_table, stars_matrix, loc='center', cellLoc='center', fontsize=15, bbox=[new_left,0,0.7,1])\n",
    "\tax_table.axis('off')\n",
    "\n",
    "\t# Title\n",
    "\tfig.suptitle(title, fontsize=18, y=0.93)\n",
    "\n",
    "\t# Save plot with high resolution\n",
    "\tplt.tight_layout()\n",
    "\tplt.savefig(save_path, dpi=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q8ugXXkGEN-g"
   },
   "outputs": [],
   "source": [
    "# Create and plot violin plot\n",
    "result = windows[windows['window_id'] == 'mean'].groupby('cohort')['pred'].apply(lambda x: np.mean(np.vstack(x), axis=1).tolist()).to_dict()\n",
    "plot_comparison_across_labels(result, x_label='Cohorts', y_label=r'Mean bifurcation parameters $a$', title='', save_path=save_path+'tasks.png')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
